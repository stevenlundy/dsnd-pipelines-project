{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be using the provided data to create a machine learning model pipeline.\n",
    "\n",
    "You must handle the data appropriately in your pipeline to predict whether an\n",
    "item is recommended by a customer based on their review.\n",
    "Note the data includes numerical, categorical, and text data.\n",
    "\n",
    "You should ensure you properly train and evaluate your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has been anonymized and cleaned of missing values.\n",
    "\n",
    "There are 8 features for to use to predict whether a customer recommends or does\n",
    "not recommend a product.\n",
    "The `Recommended IND` column gives whether a customer recommends the product\n",
    "where `1` is recommended and a `0` is not recommended.\n",
    "This is your model's target/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features can be summarized as the following:\n",
    "\n",
    "- **Clothing ID**: Integer Categorical variable that refers to the specific piece being reviewed.\n",
    "- **Age**: Positive Integer variable of the reviewers age.\n",
    "- **Title**: String variable for the title of the review.\n",
    "- **Review Text**: String variable for the review body.\n",
    "- **Positive Feedback Count**: Positive Integer documenting the number of other customers who found this review positive.\n",
    "- **Division Name**: Categorical name of the product high level division.\n",
    "- **Department Name**: Categorical name of the product department name.\n",
    "- **Class Name**: Categorical name of the product class name.\n",
    "\n",
    "The target:\n",
    "- **Recommended IND**: Binary variable stating where the customer recommends the product where 1 is recommended, 0 is not recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\n",
    "    \"data/reviews.csv\",\n",
    ")\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing features (`X`) & target (`y`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "\n",
    "# separate features from labels\n",
    "X = data.drop(\"Recommended IND\", axis=1)\n",
    "y = data[\"Recommended IND\"].copy()\n",
    "\n",
    "print(\"Labels:\", y.unique())\n",
    "print(\"Features:\")\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.1,\n",
    "    shuffle=True,\n",
    "    random_state=27,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features\n",
    "num_features = [\"Clothing ID\", \"Age\", \"Positive Feedback Count\"]\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "i = 0\n",
    "# histogram of numerical features\n",
    "for feature in num_features:\n",
    "    ax = axs[i // 3, i % 3]\n",
    "    if feature == \"Positive Feedback Count\":\n",
    "        data[feature].plot.hist(ax=ax, log=True)\n",
    "    else:\n",
    "        data[feature].plot.hist(ax=ax)\n",
    "    ax.set_title(feature)\n",
    "    ax.legend()\n",
    "    i += 1\n",
    "\n",
    "# box and whisker plot of numerical features split by Recommended IND\n",
    "for feature in num_features:\n",
    "    ax = axs[i // 3, i % 3]\n",
    "    data.boxplot(column=feature, by=\"Recommended IND\", ax=ax, vert=False)\n",
    "    if feature == \"Positive Feedback Count\":\n",
    "        ax.set_xscale(\"log\")\n",
    "    ax.set_title(\"\")\n",
    "    ax.set_title(feature)\n",
    "    ax.tick_params(axis=\"x\", rotation=0)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Features\n",
    "\n",
    "The Numerical Features are `Clothing ID`, `Age` and `Positive Feedback Count`.\n",
    "\n",
    "Looking at the distribution for `Age` shows a wide range of ages centered around 40 years old. Comparing the distributions of `Age` for recommended and not recommended reviews shows very little difference so it may not be a good predictor.\n",
    "\n",
    "Looking at the distribution for `Positive Feedback Count` shows that most reviews have very little positive feedback. Comparing the distributions of `Positive Feedback Count` for recommended and not recommended reviews shows very little difference so it may not be a good predictor.\n",
    "\n",
    "While `Clothing ID` is a numerical feature, it is actually a categorical feature. It is an identifier for the piece of clothing being reviewed. It is not useful for predicting whether a review is recommended or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features\n",
    "cat_features = [\"Division Name\", \"Department Name\", \"Class Name\"]\n",
    "\n",
    "cat_order_by_feature = {}\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "i = 0\n",
    "# bar plot of categorical features\n",
    "for feature in cat_features:\n",
    "    cat_order_by_feature[feature] = data[feature].value_counts().index\n",
    "    ax = axs[i // 3, i % 3]\n",
    "    data[feature].value_counts().reindex(cat_order_by_feature[feature]).plot.bar(\n",
    "        alpha=0.6, ax=ax\n",
    "    )\n",
    "    i += 1\n",
    "\n",
    "# categorical features as percentage by Recommended IND\n",
    "for feature in cat_features:\n",
    "    ax = axs[i // 3, i % 3]\n",
    "    data.groupby([feature, \"Recommended IND\"]).size().unstack().apply(\n",
    "        lambda x: x / x.sum(), axis=1\n",
    "    ).reindex(cat_order_by_feature[feature]).plot.bar(stacked=True, ax=ax)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features\n",
    "\n",
    "The Categorical Features are `Division Name`, `Department Name` and `Class Name`.\n",
    "\n",
    "`Division Name` has 2 categories for size: General and General Petite. The distribution of `Division Name` for recommended and not recommended is similar so it may not be a good predictor.\n",
    "\n",
    "`Department Name` has 6 categories representing types of clothes: Bottoms, Dresses, Tops, Intimate, Jackets and Trend. The distribution of `Department Name` for recommended and not recommended is similar so it may not be a good predictor.\n",
    "\n",
    "`Class Name` has 20 categories representing specific types of clothes. The distribution of `Class Name` for recommended and not recommended is similar so it may not be a good predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text features\n",
    "text_features = [\"Review Text\", \"Title\"]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# text features\n",
    "i = 0\n",
    "# histogram of text features word count\n",
    "for feature in text_features:\n",
    "    ax = axs[i // 2, i % 2]\n",
    "    # count the number of words in each review\n",
    "\n",
    "    bin_size = data[feature].str.split().apply(len).max() // 10\n",
    "    bins = range(0, data[feature].str.split().apply(len).max() + bin_size, bin_size)\n",
    "\n",
    "    length_feature = f\"{feature} word count\"\n",
    "    data[length_feature] = data[feature].str.split().apply(len)\n",
    "    for recommended in [0, 1]:\n",
    "        data[data[\"Recommended IND\"] == recommended][length_feature].plot.hist(\n",
    "            alpha=0.6, ax=ax, label=f\"Recommended {recommended}\", bins=bins\n",
    "        )\n",
    "    i += 1\n",
    "\n",
    "# box and whisker plot of text features word count split by Recommended IND\n",
    "for feature in text_features:\n",
    "    ax = axs[i // 2, i % 2]\n",
    "    data.boxplot(\n",
    "        column=f\"{feature} word count\", by=\"Recommended IND\", ax=ax, vert=False\n",
    "    )\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Features - Word Count\n",
    "\n",
    "The Text Features are `Title` and `Review Text`.\n",
    "\n",
    "Looking at the word count distribution for `Title` shows that most titles are 2 to 4 words. Comparing the distributions of `Title` word count for recommended and not recommended reviews shows that the recommended reviews tend to have slightly shorter titles. This may be a good predictor.\n",
    "\n",
    "Looking at the word count distribution for `Review Text` shows that most reviews are 40 to 90 words. Comparing the distributions of `Review Text` word count for recommended and not recommended reviews shows very little difference so it may not be a good predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Punctuation\n",
    "punctuation = [\n",
    "    (\".\", \"period\"),\n",
    "    (\"!\", \"exclamation mark\"),\n",
    "    (\"?\", \"question mark\"),\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Box and whisker plot of number of each punctuation mark per review split by Recommended IND\n",
    "for i, (p_mark, p_name) in enumerate(punctuation):\n",
    "    ax = axs[i]\n",
    "    data[f\"{p_name} count\"] = data[\"Review Text\"].str.count(re.escape(p_mark))\n",
    "    data.boxplot(column=f\"{p_name} count\", by=\"Recommended IND\", ax=ax, vert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Features - Punctaution Count\n",
    "\n",
    "Looking at the punctuation count in the review text shows that there are more exclamation points in recommended reviews. This may be a good predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    max_features=50,\n",
    "    max_df=0.9,\n",
    "    min_df=0.1,\n",
    "    ngram_range=(1, 2),\n",
    ")\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# for each recommended value, plot the most common words\n",
    "for recommended in [0, 1]:\n",
    "    # fit the vectorizer on the training data\n",
    "    X_tfidf = tfidf.fit_transform(\n",
    "        data[data[\"Recommended IND\"] == recommended][\"Review Text\"]\n",
    "    )\n",
    "    # get the most common words\n",
    "    common_words = tfidf.get_feature_names_out()\n",
    "    # plot the most common words\n",
    "    ax = axs[recommended]\n",
    "    pd.DataFrame(X_tfidf.toarray(), columns=common_words).sum().sort_values().plot.barh(\n",
    "        ax=ax, title=f\"Recommended {recommended}\"\n",
    "    )\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Features - Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "Using TF-IDF on the `Review Text` we can compare the top words between recommended and not recommended reviews. If words appear more frequently in recommended reviews than not recommended reviews, then they may be good predictors.\n",
    "\n",
    "Examples: \n",
    "\n",
    "Love - Appears 2nd most in recommended reviews and 8th most in not recommended reviews.\n",
    "\n",
    "Fabric - Appears 3rd most in not recommended reviews and 11th most in recommended reviews.\n",
    "\n",
    "Great - Appears 5th most in recommended reviews and 23rd most in not recommended reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApplyNLP(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return list(nlp.pipe(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountPOS(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, pos_tag):\n",
    "        self.pos_tag = pos_tag\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        pos_counts = []\n",
    "        for doc in X:\n",
    "            count = sum(1 for token in doc if token.pos_ == self.pos_tag)\n",
    "            pos_counts.append(count)\n",
    "        return pd.DataFrame({self.pos_tag: pos_counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether different POS frequencies are associated with the target\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "pos_tags = [\"ADJ\", \"NOUN\", \"VERB\", \"ADV\", \"ADP\", \"PRON\", \"DET\", \"NUM\"]\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "pos_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"apply_nlp\", ApplyNLP()),\n",
    "        (\n",
    "            \"pos_features\",\n",
    "            FeatureUnion([(pos, CountPOS(pos)) for pos in pos_tags]),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# Use the pipeline to transform the review text\n",
    "X_pos = pos_pipeline.fit_transform(data[\"Review Text\"])\n",
    "# convert X_pos to dataframe\n",
    "X_pos = pd.DataFrame(X_pos, columns=pos_tags)\n",
    "X_pos[\"Recommended IND\"] = data[\"Recommended IND\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(20, 10))\n",
    "for i, p in enumerate(pos_tags):\n",
    "    ax = axs[i // 4, i % 4]\n",
    "    X_pos.boxplot(column=p, by=\"Recommended IND\", ax=ax, vert=False)\n",
    "    ax.set_title(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Features - POS Tagging\n",
    "\n",
    "Using POS Tagging on the `Review Text` we can compare the top parts of speech between recommended and not recommended reviews. If parts of speech appear more frequently in recommended reviews than not recommended reviews, then they may be good predictors.\n",
    "\n",
    "Looking at the distributions, ADJ, VERB, and NUM have the most difference between recommended and not recommended reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model pipeline, we will use a combination of the features to predict whether a review is recommended or not.\n",
    "\n",
    "We will use a combination of the numerical, categorical, and text features to predict the target. For the text features, we will use the word count, punctuation count, TF-IDF, and POS Tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterFrequency(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, char):\n",
    "        self.char = char\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.DataFrame(X.apply(lambda x: len(re.findall(re.escape(self.char), x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLength(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.DataFrame(X.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCount(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.DataFrame(X.str.split().apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_feature_engineering = FeatureUnion(\n",
    "    [\n",
    "        (\"question_mark_count\", Pipeline([(\"char_freq\", CharacterFrequency(\"?\"))])),\n",
    "        (\"exclamation_mark_count\", Pipeline([(\"char_freq\", CharacterFrequency(\"!\"))])),\n",
    "        (\"text_length\", TextLength()),\n",
    "        (\"word_count\", WordCount()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lemmatizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.Series(\" \".join([token.lemma_ for token in doc]) for doc in X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import FunctionTransformer\n",
    "\n",
    "tfidf_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"lemmatizer\", Lemmatizer()),\n",
    "        (\"tfidf\", TfidfVectorizer(stop_words=\"english\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "pos_tags = [\"ADJ\", \"VERB\", \"NUM\"]\n",
    "pos_pipelines = [\n",
    "    (\n",
    "        f\"{pos}_count\",\n",
    "        Pipeline(\n",
    "            [\n",
    "                (pos, CountPOS(pos)),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    for pos in pos_tags\n",
    "]\n",
    "\n",
    "\n",
    "nlp_feature_engineering = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"dimension_reshaper\",\n",
    "            FunctionTransformer(\n",
    "                np.reshape,\n",
    "                kw_args={\"newshape\": -1},\n",
    "            ),\n",
    "        ),\n",
    "        (\"apply_nlp\", ApplyNLP()),\n",
    "        (\n",
    "            \"nlp_features\",\n",
    "            FeatureUnion(\n",
    "                [\n",
    "                    (\"tfidf\", tfidf_pipeline),\n",
    "                    *pos_pipelines,\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"text_features\", text_feature_engineering),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineering = ColumnTransformer(\n",
    "    [\n",
    "        (\"text\", text_pipeline, \"Review Text\"),\n",
    "        (\"nlp\", nlp_feature_engineering, \"Review Text\"),\n",
    "        (\"num\", num_pipeline, num_features),\n",
    "        (\"cat\", cat_pipeline, cat_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "feature_engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model_pipeline = make_pipeline(\n",
    "    feature_engineering,\n",
    "    RandomForestClassifier(random_state=27),\n",
    ")\n",
    "\n",
    "model_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_forest_pipeline = model_pipeline.predict(X_test)\n",
    "accuracy_forest_pipeline = accuracy_score(y_test, y_pred_forest_pipeline)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_forest_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model_pipeline, \"model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsnd-pipelines-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
